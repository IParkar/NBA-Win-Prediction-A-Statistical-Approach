# -*- coding: utf-8 -*-
"""NBA Win Prediction: A Statistical Approach

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tNZuH6hj1rtfU9ZP00VzdrOO3G0Jumfh


### Web Scraping and Data Visualization for Sports Analytics (NBA Data)

# New Section
"""

# Importing required packages

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import statsmodels.api as sm           # provides statistical models like ols, gmm, anova, etc...
import statsmodels.formula.api as smf  # provides a way to directly spec models from formulas
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

def scrape_nba_stats(url, id):
    try:
        # Send a GET request to the URL
        response = requests.get(url, timeout=10)
        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes
        #print(response.status_code)
        # Create a BeautifulSoup object to parse the HTML content
        soup = BeautifulSoup(response.content, 'html.parser')

        # Find the table with class 'stats_table'
        table = soup.find('table', class_='stats_table', id = id)

        if table is None:
            print("Error: Table not found on the page.")
            return None

        # Extract the headers from the table
        headers = []
        header_row = table.find('thead').find_all('tr')[-1] # Get the last header row
        for th in header_row.find_all('th')[:]:  # Skip the first empty header
            headers.append(th.text)

        # Extract the rows from the table
        rows = []
        for row in table.find('tbody').find_all('tr'):
            row_data = []
            for th in row.find_all('th'):
                th_text = th.text
                match = re.search(r'[^a-zA-Z0-9\s]', th_text)
                if match:
                  # If a special character is found, return the substring before it
                  row_data.append(th_text[:match.start()].strip())
                else:
                  # If no special character is found, return the original string
                  row_data.append(th_text)
            for td in row.find_all('td'):
                td_text = td.text
                try:
                  # Try to convert the string to a float
                  float(td_text)
                  # If successful, append the original string
                  row_data.append(td_text)
                except:
                  match = re.search(r'[^a-zA-Z0-9\s]', td_text)
                  if match:
                    # If a special character is found, return the substring before it
                    row_data.append(td_text[:match.start()].strip())
                  else:
                    # If no special character is found, return the original string
                    row_data.append(td_text)

            if len(row_data) == len(headers):
                rows.append(row_data)
            else:
                # Handle missing or extra columns
                if len(row_data) < len(headers):
                    # Add missing values
                    row_data.extend([''] * (len(headers) - len(row_data)))
                else:
                    # Remove extra columns
                    row_data = row_data[:len(headers)]
                rows.append(row_data)

        # print("Extracted rows:")
        # for row in rows:
        #     print(len(row), row)

        # Create a DataFrame from the extracted data
        df = pd.DataFrame(rows, columns=headers)

        # Drop rows where all values are empty strings
        df = df.loc[~(df == '').all(axis=1)]

        return df

    except requests.exceptions.RequestException as e:
        print(f"Error: {e}")
        return None

    except Exception as e:
        print(f"Error: {e}")
        return None

# URL of the page to scrape train data
url_train = 'https://www.basketball-reference.com/leagues/NBA_2023.html'

# Scrape the NBA player stats
east_conf_win = 'confs_standings_E'
west_conf_win = 'confs_standings_W'
overall_stats = 'per_game-team'
east_win_train = scrape_nba_stats(url_train, east_conf_win)
west_win_train = scrape_nba_stats(url_train, west_conf_win)
overall_stats_train = scrape_nba_stats(url_train, overall_stats)

def print_df(df_name):
  if df_name is not None:
      # Print the DataFrame
      print(f"\nScraped data: {df_name}")
  else:
      print(f"Failed to scrape data {df_name.name}")

print_df(east_win_train)
print_df(west_win_train)
print_df(overall_stats_train)

# URL of the page to scrape test data
url_test = 'https://www.basketball-reference.com/leagues/NBA_2024.html'

# Scrape the NBA player stats
east_win_test = scrape_nba_stats(url_test, east_conf_win)
west_win_test = scrape_nba_stats(url_test, west_conf_win)
overall_stats_test = scrape_nba_stats(url_test, overall_stats)

def print_df(df_name):
  if df_name is not None:
      # Print the DataFrame
      print("\nScraped data:")
      print(df_name)

    # Export the DataFrame to a CSV file
    #csv_filename = 'nba_stats_2024.csv'
    #df.to_csv(csv_filename, index=False)
    #print(f"\nData exported to {csv_filename}")
  else:
      print("Failed to scrape data.")

print_df(east_win_test)
print_df(west_win_test)
print_df(overall_stats_test)

player_stats_train = pd.read_excel('Team_Player_Stats_Train_2022_23.xlsx')
print(player_stats_train)

player_stats_test = pd.read_excel('Team_Player_Stats_Test_2023_24.xlsx')
print(player_stats_test)

def data_clean(win1, win2, overall, player):
  # Appending Eastern and Western conference standings table.
  win1 = win1.rename(columns = {"Eastern Conference" : "Team", "W/L%" : "Win_Percent"})
  win2 = win2.rename(columns = {"Western Conference" : "Team", "W/L%" : "Win_Percent"})
  standing_df = pd.concat([win1, win2])
  standing_df = standing_df[['Team', 'Win_Percent']]

  # Renaming columns in stats dataframe
  overall = overall.rename(columns = {"FG%" : "FG_Percent", "3P" : "Three_PointFG", "3PA" : "Three_PointAssist", "3P%" : "Three_PointFG__Percent",
                                                        "2P" : "Two_PointFG", "2PA" : "Two_PointAssist", "2P%" : "Two_PointFG__Percent", "FT%" : "FT_Percent"})

  # Merging the Conference Standings table with the Overall Statistics table to get the win percent from the conference standings tables
  stats_player = pd.merge(overall, player, on = 'Team')
  stats = pd.merge(standing_df, stats_player, on = 'Team')

  # Converting each column to numeric and handling invalid parsing error
  for col in stats.columns[1:].tolist():
      stats[col] = pd.to_numeric(stats[col], errors='coerce')

  # Convert categorical columns
  # Assuming 'Team' should be categorical
  stats['Team'] = stats['Team'].astype('category')
  return(stats)

train_stats = data_clean(east_win_train, west_win_train, overall_stats_train, player_stats_train)
test_stats = data_clean(east_win_test, west_win_test, overall_stats_test, player_stats_test)
train_stats.head()

"""#Visualizations"""

train_stats.iloc[:, 4:].corr()

#2
# Pairplot for pairwise comparisons of numerical variables
#sns.pairplot(train_stats, vars = ["MP", "FG", "FGA", "FG_Percent", "Three_PointFG", "Three_PointAssist", "Three_PointFG__Percent", "Two_PointFG", "Two_PointAssist", "Two_PointFG__Percent", "FT", "FTA", "FT_Percent", "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF", "PTS", "Height", "Weight", "Age", "Experience"], palette='viridis')
#plt.suptitle('Pairwise Relationships of Numerical Variables', y = 1.02)
#plt.show()
#print("\n")

#3
# Distribution of age using histogram
sns.histplot(train_stats['Age'], bins=20, kde=True)
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.show()
print("\n")

#3
# Distribution of height using histogram
sns.histplot(train_stats['Height'], bins=20, kde=True)
plt.title('Distribution of Height')
plt.xlabel('Height')
plt.show()
print("\n")

#4
variables = ['FG', 'FT', 'TOV', 'STL', 'Weight', 'Experience']

# Loop through each variable and create bar plots
for variable in variables:
    # Create a bar plot
    plt.figure(figsize=(8, 6))
    sns.barplot(x=train_stats[variable], y=train_stats['Win_Percent'])
    plt.title(f'Bar Plot of Win Percent vs. {variable}')
    plt.xlabel(variable)
    plt.ylabel('Win Percent')
    plt.show()

#5
#Correlation
variables = ['FG', 'Weight', 'Experience', 'TOV', 'FT', 'STL']
correlation_matrix = train_stats[variables].corr()

# Create a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Matrix of Variables')
plt.show()


#pairplot
variables = ['FG', 'Weight', 'Experience', 'TOV', 'FT', 'STL','Win_Percent']

# Create a pairplot
sns.pairplot(train_stats[variables], kind='scatter')

# Show the pairplot
plt.show()

# Train model
lm1 = smf.ols(formula='Win_Percent ~ FG + TOV + PF',
              data = train_stats)
result1 = lm1.fit()
result1.params

print(result1.summary())

lm2 = smf.ols(formula='Win_Percent ~ Height + Experience',
              data = train_stats)
result2 = lm2.fit()
result2.params

print(result2.summary())

lm3 = smf.ols(formula='Win_Percent ~ FG + FT + TOV + STL + Weight + Experience',
              data = train_stats)
result3 = lm3.fit()
result3.params

print(result3.summary())

# Testing

x_test_data = test_stats[test_stats.columns.difference(['Team', 'Win_Percent'])]
y_test_data = test_stats['Win_Percent']
yhat_test = result3.predict(x_test_data)

res = pd.concat([y_test_data, yhat_test], axis=1)
res.columns = ['True_Win_Percent', 'Predicted_Win_Percent']
res

MSE = np.square(np.subtract(y_test_data,yhat_test)).mean()
MSE